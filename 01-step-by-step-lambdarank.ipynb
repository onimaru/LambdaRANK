{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0f904db-32aa-462e-a5bb-71d821bac527",
   "metadata": {},
   "source": [
    "# LambdaRank step-by-step tutorial\n",
    "\n",
    "Step 0: Create the configuration file in `configs` folder.\n",
    "\n",
    "**Note**: The `README.md` file contain a lot of explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4fb644b-4632-4ef6-a06a-46e2f05df3cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91fa0dbe-0bea-4b9e-8ac5-eb0c1568b422",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from lambdarank.data_loader import dataloader, load_numpy_data\n",
    "from lambdarank.utils import device_loader, count_trainable_parameters\n",
    "from lambdarank.model_loader import load_model_and_optim\n",
    "from lambdarank.trainer import train_model\n",
    "from lambdarank.metrics import eval_model\n",
    "\n",
    "ngpu, device = device_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ee3f5a-e9a9-4b25-8d6a-d6abf6903211",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configurations\n",
    "\n",
    "- `run_name` (str): identifier of the run used as folder name in `runs` folder.\n",
    "- `data_parameters`:\n",
    "    - `data_path` (str): path indicating the `data` folder.\n",
    "        - `train_data`:\n",
    "            - `features_file (str)`: name of the `X_train` file.\n",
    "            - `label_file (str)`:  name of the `y_train` file.\n",
    "            - `query_file (str)`:  name of the `q_train` file.\n",
    "            - `soft_label_file (str)`:  name of the `ps_train` file.\n",
    "        - `test_data`: same pattern as `train_data`.\n",
    "        \n",
    "- `train_parameters`:\n",
    "    - `training_epochs` (int): number of training epochs.\n",
    "    - `query_batch_size` (int): number of iterations waited to update model weights.\n",
    "    - `ps_rate` (float): a number between zero and one indicating the percentage of the iterations that will use the soft label. Set this number to zero for a full conventional LambdaRank.\n",
    "    - `per_query_sample_size` (int): a number indicating the size of data randomly sampled for each query loop in training. This is specially useful if:\n",
    "        - the average number of items per query is high (50+);\n",
    "        - or the average number of relevant items per query is close to half the value of the `k` you want to optimize in your `nDCG@k`, i.e. close to half the size of the list the model will ideally rank.\n",
    "    Decreasing this value will speedup training and doing so, we recommend increasing the number of epochs to increase model generalization.\n",
    "    \n",
    "- `model_configs`:\n",
    "    - `alpha` (float): is a positive hyperparameter used to compute the lambdas:\n",
    "    $$\\lambda_{ij} = \\alpha \\left( \\frac{1}{2}\\left( 1 - S_{ij} \\right) - \\frac{1}{1 + e^{ \\alpha \\left( s_{i} - s_{j} \\right)}}\\right).$$\n",
    "        Default value is `1.0`. You can decrease it if the number of items per query is very high.\n",
    "    - `train_label_gain` (list(ints)): is a list containing the gains for each label in order of relevance. The label in `y` vector is used as an index of this list. ex: `label_gain=[0,1,3]` means a label: `0` in `y` will have `gain=0`; `1` will have `gain=1`; and `2` will have `gain=3`. Tipically $gain_{i} = 2^{l_{i}} -1$, where $l_{i}$ is the label of observation $i$, i.e. $l_{i}=y_{i}$.\n",
    "        **Note**: gains could be floats, for now only integers are implemented.\n",
    "    - `train_eval_at` (list(ints)): the values of `k` to compute `nDCG@k` used in training for train and test loaders. This is used for log purposes.\n",
    "    - `layers` (list(dicts)): the description of the Pytorch neural network you want to use in sequential mode. Ex:\n",
    "    ```python\n",
    "        {\"type\": \"Linear\", \"params\": { \"in_features\": null,\"out_features\": 16}},\n",
    "        {\"type\": \"Dropout\",\"params\": {\"p\": 0.1}},\n",
    "        {\"type\": \"LeakyReLU\",\"params\": {}},\n",
    "        {\"type\": \"Linear\",\"params\": {\"in_features\": 16,\"out_features\": 1}}\n",
    "     ```\n",
    "- `optimizer_configs` (dict): the description of the Pytorch optimizer used in training. Only `Adam` and `RMSProp` accepted for now. Ex:\n",
    "    ```python\n",
    "    {\"type\": \"Adam\",\n",
    "     \"params\": {\n",
    "         \"lr\": 0.0001,\n",
    "         \"betas\": [\n",
    "             0.9,\n",
    "             0.999\n",
    "         ],\n",
    "         \"eps\": 1e-08,\n",
    "         \"weight_decay\": 1e-06,\n",
    "         \"amsgrad\": false\n",
    "         }\n",
    "     }\n",
    "    ```\n",
    "\n",
    "- `models_path` (str): path indicating the `models` folder.\n",
    "- `model_name` (str): the name of the model (pickle) to be saved. Ex: `\"ranker\"`. A suffix will be added with the current date.\n",
    "- `label_gain` list(ints): same as `train_label_gain`, but used only as a final model evaluation.\n",
    "- `eval_at` list(ints): same as `train_eval_at`, but used only as a final model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a932f4-9a25-45c5-abb6-b81bd2909c3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_file_name = \"config_1.json\"\n",
    "with open(os.path.join(\"./configs\",config_file_name), 'r') as f:\n",
    "        run_configs = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205c6911-c4e6-4212-810b-fa7507eb9c8c",
   "metadata": {},
   "source": [
    "## Dataset:\n",
    "1. `X` and `y`: are the same as always, features matrix and label vector. The labels in `y` must be sequential integers starting in zero following an increasing order of relevance.\n",
    "2. `q`: is a vector (with the same format as `y`) where each element $q_{i}$ is a string identifier (not necessarily the query text, you can use a hashcode) indicating the query for the observations $X_{i}$ and $y_{i}$. So, the dataset must be created in a way that a label is assigned to each `(query,item)` pair, $(q_{i},X_{i}) \\rightarrow y_{i}$.  \n",
    "    Note that elements in `q` should repeat, since LambdaRank only makes pairwise comparisons of items associated with the same query.\n",
    "3. `ps`: stands for propensity score (or soft label). It is a vector with the same size as `y` and has a similar meaning too. It is a different kind of label that can be used in training, unlike the labels in `y`, these labels can be floats. If you do not have this vector available, make sure to set the following in your config file:\n",
    "    - `training_parameters > ps_rate` to `0.0`\n",
    "    - `data_parameters > train_data > soft_label_file` the same `y_train` file\n",
    "    - `data_parameters > test_data > soft_label_file` the same `y_test` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4466acde-1df3-44af-8683-f647429c9fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load numpy data\n",
    "train_data, test_data, vali_data    = load_numpy_data(run_configs[\"data_parameters\"])\n",
    "X_train, y_train, ps_train, q_train = train_data\n",
    "X_test, y_test, ps_test, q_test     = test_data\n",
    "X_vali, y_vali, ps_vali, q_vali     = vali_data\n",
    "\n",
    "# Create torch data loaders\n",
    "train_loader = dataloader(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    q_train,\n",
    "    ps_train\n",
    ")\n",
    "test_loader = dataloader(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    q_test,\n",
    "    ps_test\n",
    ")\n",
    "vali_loader = dataloader(\n",
    "    X_vali,\n",
    "    y_vali,\n",
    "    q_vali,\n",
    "    ps_vali\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c9aeef-2833-4402-a1e0-8f6890506a84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15623, 46), (15623,), (15623,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape,q_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad625189-8fb3-4891-bc5c-e450b4e44b5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(693,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Number of queries\n",
    "np.unique(q_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e35bd74-fe2e-4307-9c13-1c95c85b96b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.544011544011543"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]/np.unique(q_train).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fe93fa-b892-48a6-bc7a-6030e2beeb6f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fd3db98-609e-40eb-8a0b-0124bbf486d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " # Load model and optimizer\n",
    "model, optimizer = load_model_and_optim(\n",
    "    input_dim = train_loader.dataset.width,\n",
    "    model_configs = run_configs[\"model_configs\"],\n",
    "    optimizer_configs = run_configs[\"optimizer_configs\"],        \n",
    "    device = device,\n",
    "    ngpu = ngpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7e916ae-99e2-4df2-9c66-ecfbd139f22e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16897"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e52fc8c-b575-4db7-ada2-907eaa631bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=46, out_features=128, bias=True)\n",
       "  (1): Dropout(p=0.1, inplace=False)\n",
       "  (2): LeakyReLU(negative_slope=0.01)\n",
       "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (4): Dropout(p=0.1, inplace=False)\n",
       "  (5): LeakyReLU(negative_slope=0.01)\n",
       "  (6): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (7): Dropout(p=0.1, inplace=False)\n",
       "  (8): LeakyReLU(negative_slope=0.01)\n",
       "  (9): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (10): Dropout(p=0.1, inplace=False)\n",
       "  (11): LeakyReLU(negative_slope=0.01)\n",
       "  (12): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6225ee89-9923-4a01-b1c6-7709bb984fa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: [0.9, 0.999]\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 1e-06\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408b3dd2-1d8c-4047-8e46-a6d1073c4c62",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Note: We will run the model trainer step-by-step here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0871e591-2d7c-452e-9b3c-4624eab93b91",
   "metadata": {},
   "source": [
    "Note: This is for a binary label case.\n",
    "    \n",
    "Definitions and utilities:\n",
    "    \n",
    "- $\\alpha \\in \\mathbb{R}$\n",
    "- $s_{i} = f(x_{i})$\n",
    "- $S_{ij} \\in \\left \\{0, \\pm 1 \\right \\}$\n",
    "- $\\bar{P}_{ij} = \\frac{1}{2} \\left( 1 + S_{ij} \\right)$\n",
    "- $1 -\\bar{P}_{ij} = \\frac{1}{2} \\left( 1 - S_{ij} \\right)$\n",
    "- $P_{ij} = \\sigma \\left( s_{i},s_{j} \\right) = \\frac{1}{1+e^{-\\alpha \\left(s_{i} - s_{j} \\right)}}$\n",
    "- $\\log P_{ij} = - \\log \\left( 1+e^{-\\alpha \\left(s_{i} - s_{j} \\right)} \\right)$\n",
    "- $1- P_{ij} = P_{ji} = \\frac{1}{1+e^{\\alpha \\left(s_{i} - s_{j} \\right)}} = \\frac{ e^{-\\alpha \\left(s_{i} - s_{j} \\right)} }{1+e^{-\\alpha \\left(s_{i} - s_{j} \\right)}}$\n",
    "- $\\log \\left( 1 - P_{ij} \\right) = - \\alpha \\left(s_{i} - s_{j} \\right) - \\log \\left( 1+e^{-\\alpha \\left(s_{i} - s_{j} \\right)} \\right)$\n",
    "    \n",
    "\n",
    "The binary cross-entropy loss assumes the form:\n",
    "\n",
    "\\begin{align*}C &= - \\bar{P}_{ij} \\log{P_{ij}} - \\left(1 - \\bar{P}_{ij} \\right) \\log{ \\left(1 - P_{ij} \\right ) } \\\\  &= \\bar{P}_{ij} \\log \\left( 1+e^{-\\alpha \\left(s_{i} - s_{j} \\right)} \\right) - \\left(1 - \\bar{P}_{ij} \\right) \\left[ - \\alpha \\left(s_{i} - s_{j} \\right) - \\log \\left( 1+e^{-\\alpha \\left(s_{i} - s_{j} \\right)} \\right) \\right] \\\\  &= \\bar{P}_{ij} \\log \\left( 1+e^{-\\alpha \\left(s_{i} - s_{j} \\right)} \\right) - \\bar{P}_{ij} \\log \\left( 1+e^{-\\alpha \\left(s_{i} - s_{j} \\right)} \\right) + \\log \\left( 1+e^{-\\alpha \\left(s_{i} - s_{j} \\right)} \\right) + \\alpha \\left(s_{i} - s_{j} \\right) \\left( 1 - \\bar{P}_{ij} \\right ) \\\\ &= \\log \\left( 1+e^{-\\alpha \\left(s_{i} - s_{j} \\right)} \\right) + \\alpha \\left(s_{i} - s_{j} \\right) \\left( 1 - \\bar{P}_{ij} \\right ) \\\\ &= \\log \\left( 1+e^{-\\alpha \\left(s_{i} - s_{j} \\right)} \\right) + \\frac{1}{2} \\left( 1 - S_{ij} \\right ) \\alpha \\left(s_{i} - s_{j} \\right) \\\\\\end{align*}\n",
    "\n",
    "\n",
    "We can have the following situations:\n",
    "- If $S_{ij} = 0, \\implies C(S_{ij}=0) = \\log \\left( 1+e^{-\\alpha \\left(s_{i} - s_{j} \\right)} \\right) + \\frac{1}{2} \\alpha \\left(s_{i} - s_{j} \\right)$\n",
    "\n",
    "- If $S_{ij} = -1, \\implies C(S_{ij}=-1) = \\log \\left( 1+e^{-\\alpha \\left(s_{i} - s_{j} \\right)} \\right) + 1 \\alpha \\left(s_{i} - s_{j} \\right)$\n",
    "\n",
    "- If $S_{ij} = +1, \\implies C(S_{ij}=+1) = \\log \\left( 1+e^{-\\alpha \\left(s_{i} - s_{j} \\right)} \\right) + 0\\alpha \\left(s_{i} - s_{j} \\right)$ \n",
    "\n",
    "In order to use gradient descent, we need to compute it w.r.t. the model's parameters $\\theta_{k}$ to update them:\n",
    "    \n",
    "$$\n",
    "\\theta_{k} \\leftarrow \\theta_{k} - \\gamma \\nabla_{\\theta_{k}}C\n",
    "$$\n",
    "\n",
    "We first need to compute the derivative of the cost w.r.t. the model's outputs:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial C}{\\partial s_{i}} = \\alpha \\left( \\frac{1}{2}\\left( 1 - S_{ij} \\right) - \\frac{1}{1 + e^{ \\alpha \\left( s_{i} - s_{j} \\right)}}\\right) = - \\frac{\\partial C}{\\partial s_{j}}\n",
    "$$\n",
    "\n",
    "And since the outputs are functions of the parameters $\\theta$, the gradient is\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\nabla_{\\theta_{k}}C = \\frac{\\partial C}{\\partial \\theta_{k}} &= \\frac{\\partial C}{\\partial s_{i}}\\frac{\\partial s_{i}}{\\partial \\theta_{k}} + \\frac{\\partial C}{\\partial s_{j}}\\frac{\\partial s_{j}}{\\partial \\theta_{k}} \\\\\n",
    " &=  \\frac{\\partial C}{\\partial s_{i}} \\left( \\frac{\\partial s_{i}}{\\partial \\theta_{k}} -\\frac{\\partial s_{j}}{\\partial \\theta_{k}} \\right)\\\\\n",
    " &= \\left[ \\alpha \\left( \\frac{1}{2}\\left( 1 - S_{ij} \\right) - \\frac{1}{1 + e^{ \\alpha \\left( s_{i} - s_{j} \\right)}}\\right) \\right] \\left( \\frac{\\partial s_{i}}{\\partial \\theta_{k}} -\\frac{\\partial s_{j}}{\\partial \\theta_{k}} \\right).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "If were not for the term in the brackets this would look like a conventional gradient. This term is called `lambdas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73c931fa-4cf5-4859-822a-1ab1c59160cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 16897\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir=f\"runs/{run_configs['run_name']}\")\n",
    "print(f\"Number of trainable parameters: {count_trainable_parameters(model)}\")\n",
    "writer.add_text('Configs', str(run_configs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "40fd81f3-f41e-4bde-8eaf-70c183f72e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import numpy as np\n",
    "from lambdarank.metrics import max_dcg_k, eval_model, compute_ndcg\n",
    "from lambdarank.trainer import sample_per_query_data, max_ndcg_tensor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85c572de-439e-429e-a673-7f329038d499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just a helping function\n",
    "def format_data(data):\n",
    "    X, y, ps = data\n",
    "    return X[0], y[0], ps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1440cdb9-d35c-4d53-8d30-a5fc45443c2a",
   "metadata": {},
   "source": [
    "Let us get some data example and work with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed3d0b8e-efea-4ef0-a673-21bda2dad56d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha = model.alpha\n",
    "for query_epoch, data in enumerate(train_loader):\n",
    "    X, y, _ = format_data(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa5bbc6a-e3ea-4b6d-afd4-f68e550a39db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 46]), torch.Size([5]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample, y_sample, _ = sample_per_query_data(X,y,y,per_query_sample_size=5)\n",
    "X_sample.shape,y_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19208bb9-604c-413c-abee-cb441c031aeb",
   "metadata": {},
   "source": [
    "Now, we need to compute the following:\n",
    "\n",
    "$$\\lambda_{ij} = \\alpha \\left( \\frac{1}{2}\\left( 1 - S_{ij} \\right) - \\frac{1}{1 + e^{ \\alpha \\left( s_{i} - s_{j} \\right)}}\\right) \\left| \\Delta NDCG \\right|_{ij}$$\n",
    "\n",
    "$$S_{ij} = ?$$\n",
    "\n",
    "$$\\left| \\Delta NDCG \\right|_{ij}=?$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6fee7279-6cce-4a71-a083-c7a28facb25b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 1., 0., 0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52c609bb-621f-42cd-bd31-e0c7e7dfd999",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0672],\n",
       "        [-0.1669],\n",
       "        [-0.1705],\n",
       "        [ 0.1853],\n",
       "        [-0.1285]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = model(X_sample.to(device))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "08f4bc18-c624-4bfd-98b4-dc7736ecdd15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1 -> 0.0000\n",
      "k=2 -> 0.0000\n",
      "k=3 -> 0.0000\n",
      "k=4 -> 0.3274\n",
      "k=5 -> 0.3274\n",
      "k=6 -> 0.3274\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,7):\n",
    "    print(f\"k={k} -> {compute_ndcg(s,y_sample,k):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02f24259-cf43-4cc3-a7d5-2c43586c04ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.4751, 0.4742, 0.5628, 0.4847],\n",
       "        [0.5249, 0.5000, 0.4991, 0.5872, 0.5096],\n",
       "        [0.5258, 0.5009, 0.5000, 0.5880, 0.5105],\n",
       "        [0.4372, 0.4128, 0.4120, 0.5000, 0.4222],\n",
       "        [0.5153, 0.4904, 0.4895, 0.5778, 0.5000]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pji = 1.0 / (1.0 + torch.exp(alpha * (s - s.t())))\n",
    "Pji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de83430a-4bb5-41e0-818f-79cec653ec7b",
   "metadata": {},
   "source": [
    "Relevance difference or Gain difference: $S_{ij}$\n",
    "If label if binary, relevance is equal gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20127de6-4772-4c4b-94c5-c27c96457f2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0., -2., -1.,  0.,  0.],\n",
       "        [ 2.,  0.,  1.,  2.,  2.],\n",
       "        [ 1., -1.,  0.,  1.,  1.],\n",
       "        [ 0., -2., -1.,  0.,  0.],\n",
       "        [ 0., -2., -1.,  0.,  0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relevance difference\n",
    "rel_diff = y_sample.view(-1,1) - y_sample.view(-1,1).t()\n",
    "rel_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c75ab92-b444-4961-ac2c-8cb6240f0b87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, -3, -1,  0,  0],\n",
       "        [ 3,  0,  2,  3,  3],\n",
       "        [ 1, -2,  0,  1,  1],\n",
       "        [ 0, -3, -1,  0,  0],\n",
       "        [ 0, -3, -1,  0,  0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gain difference\n",
    "gain_diff = model.gain[y_sample.long()].reshape(-1,1) - model.gain[y_sample.long()].reshape(1,-1)\n",
    "gain_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72d4fe92-b0c2-4c4c-8359-dad0f23ef32f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, -1, -1,  0,  0],\n",
       "        [ 1,  0,  1,  1,  1],\n",
       "        [ 1, -1,  0,  1,  1],\n",
       "        [ 0, -1, -1,  0,  0],\n",
       "        [ 0, -1, -1,  0,  0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sij = (rel_diff > 0).int() - (rel_diff < 0).int()\n",
    "Sij"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed91267d-727e-47ee-87b5-ea8978691a98",
   "metadata": {},
   "source": [
    "**Compute $\\left| \\Delta NDCG \\right|_{ij}$**:\n",
    "\n",
    "Sort list by $s_{i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fccffc37-e41b-4a2f-86d6-89343214627f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [4],\n",
       "        [5],\n",
       "        [1],\n",
       "        [3]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_order = (s.reshape(-1).argsort(descending=True).argsort() + 1).reshape(-1, 1)\n",
    "rank_order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54e056e-96a6-4d76-ba74-cee72e8de3e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Score decay by position based on the prediction order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1603855-4e10-4eb6-8ec1-b59247492c20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.2003,  0.2441, -0.3691,  0.1309],\n",
       "        [-0.2003,  0.0000,  0.0438, -0.5693, -0.0693],\n",
       "        [-0.2441, -0.0438,  0.0000, -0.6131, -0.1131],\n",
       "        [ 0.3691,  0.5693,  0.6131,  0.0000,  0.5000],\n",
       "        [-0.1309,  0.0693,  0.1131, -0.5000,  0.0000]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decay_diff = (1.0 / torch.log2(rank_order + 1.0)) - (1.0 / torch.log2(rank_order.t() + 1.0))\n",
    "decay_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94afde52-bb27-4660-aa4f-bb4f9bf67e07",
   "metadata": {},
   "source": [
    "Compute Max DCG normalization factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "38fa2dff-75fe-49db-a494-e6573eaff097",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.5850, 2.0000, 2.3219, 2.5850])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 5\n",
    "discount = torch.log2(torch.arange(start=1, end=k+1, step=1) + 1)\n",
    "discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0c7c07af-f450-4f6e-98cc-1fe94bd4b2db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_label_tensor = model.gain[y_sample.long()].sort(descending=True)[0][:k]\n",
    "sorted_label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cba435c1-fe06-4859-9489-9c35adea25e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0000, 0.6309, 0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_label_tensor / discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f8159271-53b2-478b-8da3-9190938ba963",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.6309), tensor(0.2754))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ndcg_value = (sorted_label_tensor / discount).sum()\n",
    "max_ndcg_value, 1.0/max_ndcg_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fd90b3a6-27ea-44bf-a188-464169ff5c3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:1 -> 0.3333\n",
      "k:2 -> 0.2754\n",
      "k:3 -> 0.2754\n",
      "k:4 -> 0.2754\n",
      "k:5 -> 0.2754\n",
      "k:6 -> 0.2754\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,7):\n",
    "    ndcg_norm = 1.0 / max_ndcg_tensor(y_sample,k,model.gain)\n",
    "    print(f\"k:{k} -> {ndcg_norm.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "86609ce3-cd23-441f-8499-82ff10c2c2ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2754)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 5\n",
    "ndcg_norm = 1.0 / max_ndcg_tensor(y_sample,k,model.gain)\n",
    "ndcg_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53283314-eb4a-404d-ab3a-8a27180734fa",
   "metadata": {},
   "source": [
    "$\\left| \\Delta NDCG \\right|_{ij}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "877ff4c5-103f-4a0a-babb-73eaeab41a91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1655, 0.0672, 0.0000, 0.0000],\n",
       "        [0.1655, 0.0000, 0.0241, 0.4704, 0.0573],\n",
       "        [0.0672, 0.0241, 0.0000, 0.1689, 0.0312],\n",
       "        [0.0000, 0.4704, 0.1689, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0573, 0.0312, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_ndcg = torch.abs(ndcg_norm * gain_diff.to(device) * decay_diff)\n",
    "delta_ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944edfec-e1b1-4058-9e12-2a7898cd88b3",
   "metadata": {},
   "source": [
    "Finally compute $\\lambda_{ij}= \\alpha \\left( \\frac{1}{2}\\left( 1 - S_{ij} \\right) - \\frac{1}{1 + e^{ \\alpha \\left( s_{i} - s_{j} \\right)}}\\right) \\left| \\Delta NDCG \\right|_{ij}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a9ba7312-d428-4ddd-ab8e-ad23700e0376",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0869,  0.0353, -0.0000,  0.0000],\n",
       "        [-0.0869,  0.0000, -0.0120, -0.2762, -0.0292],\n",
       "        [-0.0353,  0.0120,  0.0000, -0.0993, -0.0159],\n",
       "        [ 0.0000,  0.2762,  0.0993,  0.0000,  0.0000],\n",
       "        [-0.0000,  0.0292,  0.0159, -0.0000,  0.0000]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_matrix = (alpha * delta_ndcg) * (0.5 * (1 - Sij.to(device)) - Pji).detach()\n",
    "lambda_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b2c6fa7b-2163-42b8-83b2-39125059af82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1222],\n",
       "        [-0.4043],\n",
       "        [-0.1385],\n",
       "        [ 0.3755],\n",
       "        [ 0.0451]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_update = (\n",
    "    (alpha * delta_ndcg) * (0.5 * (1 - Sij.to(device)) - Pji)\n",
    ").sum(dim=1,keepdim=True)\n",
    "lambda_update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53967b9-088d-4cbb-b696-b045af6920fc",
   "metadata": {},
   "source": [
    "Now we can use the lambda to update the model's weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cc6245ab-7c7c-47b6-843a-d0305f296a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.backward(lambda_update)\n",
    "optimizer.step()\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "523ac6f9-a361-4279-93fb-eef258510ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    s_new = model(X_sample.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e5ab9a35-c804-490d-9975-978bc453a7d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 1., 0., 0.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3d131b10-51ed-4531-86f8-853e93389ce8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0672],\n",
       "        [-0.1669],\n",
       "        [-0.1705],\n",
       "        [ 0.1853],\n",
       "        [-0.1285]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Old value\n",
    "s.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "67013e08-abb5-479f-a4df-17da84c14ef5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1748],\n",
       "        [-0.2454],\n",
       "        [ 0.1484],\n",
       "        [-0.0591],\n",
       "        [-0.2722]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c12b1a3d-986a-4703-aa18-e4731f1a5721",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2420],\n",
       "        [-0.0784],\n",
       "        [ 0.3189],\n",
       "        [-0.2443],\n",
       "        [-0.1437]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_new - s.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4fac47f5-5f14-48c5-81bb-18cc10891378",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [4],\n",
       "        [2],\n",
       "        [3],\n",
       "        [5]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_order = (s_new.reshape(-1).argsort(descending=True).argsort() + 1).reshape(-1, 1)\n",
    "rank_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8042c304-8d16-4be2-8a03-c7c515a54b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1 -> 0.0000\n",
      "k=2 -> 0.2398\n",
      "k=3 -> 0.2398\n",
      "k=4 -> 0.5672\n",
      "k=5 -> 0.5672\n",
      "k=6 -> 0.5672\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,7):\n",
    "    print(f\"k={k} -> {compute_ndcg(s_new,y_sample,k):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8975c799-c5c4-413c-8672-4a38c36d9935",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training algorithm\n",
    "\n",
    "Putting it all together:\n",
    "\n",
    "```python\n",
    "def train_model(model,optimizer,train_loader,test_loader,epochs,batch_size,ps_rate,per_query_sample_size,device,writer):\n",
    "    \"\"\"\n",
    "    Trains a ranking model using a Learn to Rank approach, evaluating its performance over a specified number of epochs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The neural network model to be trained.\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        The optimization algorithm used to update model parameters.\n",
    "    train_loader : torch.utils.data.DataLoader\n",
    "        DataLoader for the training dataset, which yields batches of data.\n",
    "    test_loader : torch.utils.data.DataLoader\n",
    "        DataLoader for the testing dataset, used for evaluation.\n",
    "    epochs : int\n",
    "        Number of full training cycles on the entire dataset.\n",
    "    batch_size : int\n",
    "        Number of queries per batch for updating model parameters.\n",
    "    ps_rate : float\n",
    "        Probability rate at which the sampled data uses propensity scores rather than actual relevance scores.\n",
    "    per_query_sample_size : int\n",
    "        The number of instances to sample per query for training.\n",
    "    device : torch.device\n",
    "        The device (CPU or GPU) on which the computations will be performed.\n",
    "    writer : torch.utils.tensorboard.SummaryWriter\n",
    "        A writer for logging metrics and training progress to TensorBoard.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : torch.nn.Module\n",
    "        The trained model.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function trains a ranking model via grouping query results, applying preference pairs, and optimizing with gradient updates.\n",
    "    Propensity-based sampling and relevance-based sampling are used interchangeably based on the ps_rate.\n",
    "    Performance metrics for each epoch are logged using TensorBoard.\n",
    "\n",
    "    The function is part of a machine learning pipeline for ranking tasks in an e-commerce or similar environment where models\n",
    "    are trained to automatically rank items based on predicted scores generated from user interaction data.\n",
    "    \"\"\"\n",
    "    alpha = model.alpha\n",
    "    scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "    for epoch in tqdm(range(1,epochs+1)):\n",
    "        grad_batch, y_pred_batch = [], []\n",
    "        query_count = 0\n",
    "        for query_epoch, train_data in enumerate(train_loader):\n",
    "            X_train_, y_train_, ps_train_ = train_data\n",
    "            X_train_, y_train_, ps_train_ = X_train_[0], y_train_[0], ps_train_[0]\n",
    "            if y_train_.sum() == 0.0:\n",
    "                continue\n",
    "            \n",
    "            X_train,y_train,ps_train = sample_per_query_data(X_train_,y_train_,ps_train_,per_query_sample_size)\n",
    "\n",
    "            y_pred = model(X_train.to(device))\n",
    "            y_pred_batch.append(y_pred)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                if np.random.rand() < ps_rate:\n",
    "                    rel_diff = ps_train.view(-1,1) - ps_train.view(-1,1).t()\n",
    "                    gain_diff = rel_diff\n",
    "                else:\n",
    "                    rel_diff = y_train.view(-1,1) - y_train.view(-1,1).t()\n",
    "                    gain_diff = model.gain[y_train.long()].reshape(-1,1) - model.gain[y_train.long()].reshape(1,-1)\n",
    "                    \n",
    "                Sij = (rel_diff > 0).int() - (rel_diff < 0).int()\n",
    "                Pji = 1.0 / (1.0 + torch.exp(alpha * (y_pred - y_pred.t())))\n",
    "\n",
    "                delta_ndcg = compute_delta_ndcg(y_pred,y_train,gain_diff,len(y_train),model.gain,device)\n",
    "                lambda_update = compute_lambda(alpha,delta_ndcg,Sij,Pji,device)\n",
    "                grad_batch.append(lambda_update)\n",
    "                \n",
    "                writer.add_scalar(\"Lambda/train\", lambda_update.detach().mean(), epoch * (query_epoch+1))\n",
    "                writer.add_scalar(\"Pji/train\", Pji.detach().mean(), epoch * (query_epoch+1))\n",
    "                writer.add_scalar(\"Abs_delta_nDCG/train\", delta_ndcg.detach().mean(), epoch * (query_epoch+1))\n",
    "            \n",
    "            query_count += 1\n",
    "            if query_count % batch_size == 0:\n",
    "                for grad,y_pred in zip(grad_batch,y_pred_batch):\n",
    "                    y_pred.backward(grad)\n",
    "                optimizer.step()\n",
    "                model.zero_grad()\n",
    "                grad_batch, y_pred_batch = [], []\n",
    "        \n",
    "        for k in model.eval_at:\n",
    "            writer.add_scalar(f\"nDCG@{k}/train\", eval_model(model,train_loader,k,device), epoch)\n",
    "            writer.add_scalar(f\"nDCG@{k}/test\", eval_model(model,test_loader,k,device), epoch)\n",
    "    \n",
    "        scheduler.step()\n",
    "        writer.add_scalar(f\"LR\", scheduler.get_last_lr()[0], epoch)\n",
    "    return model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a405180-cb6c-43bf-8b96-576876f06319",
   "metadata": {},
   "source": [
    "## Running experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31c94a24-074b-4311-9cef-ceb36386b0d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Number of trainable parameters: 16897\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:13<00:00, 13.59s/it]\n",
      "ndcg@1   -> train: 0.3990 | test: 0.3810 | vali: 0.4222\n",
      "ndcg@3   -> train: 0.4260 | test: 0.4433 | vali: 0.4730\n",
      "ndcg@10  -> train: 0.5587 | test: 0.5732 | vali: 0.6085\n",
      "ndcg@50  -> train: 0.6365 | test: 0.6503 | vali: 0.6743\n"
     ]
    }
   ],
   "source": [
    "!python app.py --config config_1.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c73bd92-b20d-4373-bbce-4ca5ef45d0d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Number of trainable parameters: 9793\n",
      "100%|███████████████████████████████████████████| 10/10 [02:05<00:00, 12.55s/it]\n",
      "ndcg@1   -> train: 0.5325 | test: 0.5357 | vali: 0.5133\n",
      "ndcg@3   -> train: 0.5718 | test: 0.5666 | vali: 0.5766\n",
      "ndcg@10  -> train: 0.6900 | test: 0.6829 | vali: 0.7035\n",
      "ndcg@50  -> train: 0.7408 | test: 0.7187 | vali: 0.7489\n"
     ]
    }
   ],
   "source": [
    "!python app.py --config config_2.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a31ddb65-c3af-4390-9e97-cff0ecb02e75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Number of trainable parameters: 417\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:11<00:00, 11.33s/it]\n",
      "ndcg@1   -> train: 0.5029 | test: 0.5262 | vali: 0.4800\n",
      "ndcg@3   -> train: 0.5483 | test: 0.5677 | vali: 0.5509\n",
      "ndcg@10  -> train: 0.6699 | test: 0.6787 | vali: 0.6708\n",
      "ndcg@50  -> train: 0.7269 | test: 0.7308 | vali: 0.7173\n"
     ]
    }
   ],
   "source": [
    "!python app.py --config config_3.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fd9ac9-8b96-497a-945b-55b3f6ed4b0f",
   "metadata": {},
   "source": [
    "## Load and check model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4d6e52d-9b75-4db7-85f8-ce668ea0e74f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def max_ndcg_tensor(y,k,gain=None):\n",
    "    k = min(len(y),k)\n",
    "    discount = torch.log2(torch.arange(start=1, end=k+1, step=1) + 1)\n",
    "    \n",
    "    if gain is None:\n",
    "        sorted_label_tensor = y.sort(descending=True)[0][:k]\n",
    "    else:\n",
    "        sorted_label_tensor = gain[y.long()].sort(descending=True)[0][:k]\n",
    "    \n",
    "    return (sorted_label_tensor / discount).sum()\n",
    "\n",
    "def compute_block_ndcg(y_pred,y,k,gain,device):\n",
    "    rank_order = (y_pred.reshape(-1).argsort(descending=True).argsort() + 1).reshape(-1, 1)\n",
    "    rank_order_idx = torch.argwhere(rank_order<=k)[:,0]\n",
    "    rank_order_ = rank_order[rank_order_idx]\n",
    "    decay = 1.0 / torch.log2(rank_order_ + 1.0)\n",
    "    max_ndcg = max_ndcg_tensor(y,k,gain)\n",
    "    if max_ndcg == torch.tensor(0.0):\n",
    "        ndcg_norm = torch.tensor(0.0)\n",
    "    else:\n",
    "        ndcg_norm = 1.0 / max_ndcg\n",
    "    if gain is None:\n",
    "        block_gain = y[rank_order_idx].view(-1,1)\n",
    "    else:\n",
    "        block_gain = gain[y[rank_order_idx].long()].reshape(-1,1)\n",
    "    ndcg = ndcg_norm * (block_gain * decay).sum()\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69f2a451-33be-438b-994a-1158363a47ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_file_name = \"config_3.json\"\n",
    "with open(os.path.join(\"./configs\",config_file_name), 'r') as f:\n",
    "        run_configs = json.load(f)\n",
    "\n",
    "# Load model and optimizer\n",
    "model, optimizer = load_model_and_optim(\n",
    "    input_dim = train_loader.dataset.width,\n",
    "    model_configs = run_configs[\"model_configs\"],\n",
    "    optimizer_configs = run_configs[\"optimizer_configs\"],        \n",
    "    device = device,\n",
    "    ngpu = ngpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63948cfe-716e-497f-b7b4-faeffd6b2b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./models/ranker_03\",weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1a1b0a1-1b93-416c-b3dc-446d2f1fc2ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vali_ndcg,random_ndcg = [[],[]]\n",
    "k = 10\n",
    "with torch.no_grad():\n",
    "    for _, data in enumerate(vali_loader):\n",
    "        X, y, _ = format_data(data)\n",
    "        preds = model(X.to(device)).detach().cpu()\n",
    "        random_preds = torch.randn((len(y),1))\n",
    "        vali_ndcg.append(compute_block_ndcg(preds,y,k,model.gain,device).item())\n",
    "        random_ndcg.append(compute_block_ndcg(random_preds,y,k,model.gain,device).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfb39c31-2b27-4216-8711-fdd5943000fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg@10  -> validation: 0.7006 | random sort: 0.5315\n"
     ]
    }
   ],
   "source": [
    "print(f\"ndcg@{k:<4}-> validation: {np.mean(vali_ndcg):.4f} | random sort: {np.mean(random_ndcg):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7f21ab-9973-4575-95a4-f124ae1aaf9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
